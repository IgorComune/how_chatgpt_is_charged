{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from psw import MyClass # access information\n",
    "import openai # openai lib\n",
    "import tiktoken # lib used by openai to tokenize words\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "access = MyClass()\n",
    "openai.api_key = access.key # your key\n",
    "model = access.model['model']['name'] # or 'gpt-3.5-turbo-0613'\n",
    "input_cost = access.model['model']['input'] / 1000 # OpenIA charges by 1k tokens, dividing by 1000, will bring the cost by token\n",
    "output_cost = access.model['model']['output'] / 1000 # same thing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0000015\n"
     ]
    }
   ],
   "source": [
    "print(f'{input_cost:.7f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0000020\n"
     ]
    }
   ],
   "source": [
    "print(f'{output_cost:.7f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_text():\n",
    "    text = input(\"user: \")\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "whats the scape velocity of mars orbit?\n",
      "[{'content': 'whats the scape velocity of mars orbit?'}]\n"
     ]
    }
   ],
   "source": [
    "text = input_text()\n",
    "text_2 = [{'content': text}]\n",
    "print(text)\n",
    "print(text_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function was copied from OpenAI Github account: https://github.com/openai/openai-cookbook/blob/main/examples/How_to_count_tokens_with_tiktoken.ipynb\n",
    "def num_tokens_from_messages(messages, model=model):\n",
    "    text = [{'content': messages}] # modification made by me to deal with the inputed text\n",
    "    try:\n",
    "        encoding = tiktoken.encoding_for_model(model)\n",
    "    except KeyError:\n",
    "        print(\"Warning: model not found. Using cl100k_base encoding.\")\n",
    "        encoding = tiktoken.get_encoding(\"cl100k_base\")\n",
    "    if model in {\n",
    "            \"gpt-3.5-turbo-0613\",\n",
    "            \"gpt-3.5-turbo-16k-0613\",\n",
    "            \"gpt-4-0314\",\n",
    "            \"gpt-4-32k-0314\",\n",
    "            \"gpt-4-0613\",\n",
    "            \"gpt-4-32k-0613\",\n",
    "            }:\n",
    "        tokens_per_message = 3\n",
    "        tokens_per_name = 1\n",
    "    elif model == \"gpt-3.5-turbo-0301\":\n",
    "        tokens_per_message = 4  # every message follows <|start|>{role/name}\\n{content}<|end|>\\n\n",
    "        tokens_per_name = -1  # if there's a name, the role is omitted\n",
    "    elif \"gpt-3.5-turbo\" in model:\n",
    "        print(\"Warning: gpt-3.5-turbo may update over time. Returning num tokens assuming gpt-3.5-turbo-0613.\")\n",
    "        return num_tokens_from_messages(messages, model=\"gpt-3.5-turbo-0613\")\n",
    "    elif \"gpt-4\" in model:\n",
    "        print(\"Warning: gpt-4 may update over time. Returning num tokens assuming gpt-4-0613.\")\n",
    "        return num_tokens_from_messages(messages, model=\"gpt-4-0613\")\n",
    "    else:\n",
    "        raise NotImplementedError(\n",
    "            f\"\"\"num_tokens_from_messages() is not implemented for model {model}. See https://github.com/openai/openai-python/blob/main/chatml.md for information on how messages are converted to tokens.\"\"\"\n",
    "        )\n",
    "    num_tokens = 0\n",
    "    for message in text:\n",
    "        num_tokens += tokens_per_message\n",
    "        for key, value in message.items():\n",
    "            num_tokens += len(encoding.encode(value))\n",
    "            if key == \"name\":\n",
    "                num_tokens += tokens_per_name\n",
    "    num_tokens += 3  # every reply is primed with <|start|>assistant<|message|>\n",
    "    return num_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding = tiktoken.encoding_for_model(model) # the encoder for our model 'gpt-3.5-turbo-0613'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The text: \n",
      "whats the scape velocity of mars orbit? \n",
      "contains 9 tokens\n"
     ]
    }
   ],
   "source": [
    "text_example = text # extract the text\n",
    "n_tokens_example = len(encoding.encode(text)) # count the number of tokens\n",
    "\n",
    "print(f'The text: \\n{text_example} \\ncontains {n_tokens_example} tokens')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'whats the scape velocity of mars orbit?'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens_per_message = 3 # constant\n",
    "tokens_per_name = 1 # constant\n",
    "\n",
    "num_tokens = 0 # token counter\n",
    "\n",
    "for message in text: # couts the number of messages inside the \n",
    "    num_tokens += tokens_per_message # add 3 tokens to the number of tokens (considering the model 'gpt-3.5-turbo-0613')\n",
    "    for key, value in message.items(): # key is the content value is the text inside content\n",
    "        num_tokens += len(encoding.encode(value)) # adds the number of tokens encoded to the total number of tokens\n",
    "        if key == \"name\":\n",
    "            num_tokens += tokens_per_name # if 'name' is in key, it adds 1\n",
    "num_tokens += 3  # every reply is primed with <|start|>assistant<|message|>\n",
    "num_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_tokens_from_messages(text, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00002250\n"
     ]
    }
   ],
   "source": [
    "print(f'{15 * input_cost:.8f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explanation\n",
    "Our text contains 9 tokens,\n",
    "And 3 more tokens are added because of the model\n",
    "and 3 more tokens are added because of the reply\n",
    "\n",
    "Total: 15\n",
    "\n",
    "The cost of this query will be 15 * input_cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Input Cost: 0.00002250\n"
     ]
    }
   ],
   "source": [
    "total_example = 15 * input_cost\n",
    "print(f'Total Input Cost: {total_example:.8f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat(model, text, max_tokens=500):\n",
    "  response = openai.ChatCompletion.create(\n",
    "    model=model,\n",
    "    messages=[{\"role\": \"user\", \"content\" : text}],\n",
    "    max_tokens=max_tokens\n",
    "  ) \n",
    "  return response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# API Response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<OpenAIObject chat.completion id=chatcmpl-7qVnZ8CEkYL9ZyPuAg0GPmC48GM9z at 0x167a6191620> JSON: {\n",
       "  \"id\": \"chatcmpl-7qVnZ8CEkYL9ZyPuAg0GPmC48GM9z\",\n",
       "  \"object\": \"chat.completion\",\n",
       "  \"created\": 1692749645,\n",
       "  \"model\": \"gpt-3.5-turbo-0613\",\n",
       "  \"choices\": [\n",
       "    {\n",
       "      \"index\": 0,\n",
       "      \"message\": {\n",
       "        \"role\": \"assistant\",\n",
       "        \"content\": \"The escape velocity of Mars orbit is about 5.03 kilometers per second (km/s), or approximately 11,223 miles per hour (mph).\"\n",
       "      },\n",
       "      \"finish_reason\": \"stop\"\n",
       "    }\n",
       "  ],\n",
       "  \"usage\": {\n",
       "    \"prompt_tokens\": 16,\n",
       "    \"completion_tokens\": 31,\n",
       "    \"total_tokens\": 47\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = chat(model, 'whats the scape velocity of mars orbit?')\n",
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_cost = []\n",
    "out_cost = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chatbot():\n",
    "    while True:\n",
    "        text = input_text()\n",
    "        if text == 'EXIT':\n",
    "            break\n",
    "        else:\n",
    "            pass\n",
    "        \n",
    "        print(f'Input Text: {text}')\n",
    "        input_text_cost = num_tokens_from_messages(text, model) * input_cost\n",
    "        print(f'Input Cost: {input_text_cost:.8f}')\n",
    "        in_cost.append(input_text_cost)\n",
    "        print('-' * 30)\n",
    "        r = chat(model, text, max_tokens=100)\n",
    "        \n",
    "        output_text = r['choices'][0]['message']['content'].strip()\n",
    "        print(f'Output: {output_text}')\n",
    "        output_text_cost = r['usage']['completion_tokens'] * output_cost\n",
    "        out_cost.append(output_text_cost)\n",
    "        print(f'Output_cost: {output_text_cost:.8f}')\n",
    "        print('-' * 30)\n",
    "        print(f'Total cost of this query: {output_text_cost + input_text_cost:.8f}')\n",
    "        print(f'Total cost of this Runtime: {sum(in_cost) + sum(out_cost):.8f}')\n",
    "        print('-' * 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Text: whats the scape velocity of mars orbit?\n",
      "Input Cost: 0.00002250\n",
      "------------------------------\n",
      "Output: The escape velocity of Mars' orbit is approximately 5.03 kilometers per second (11,186 miles per hour).\n",
      "Output_cost: 0.00004800\n",
      "------------------------------\n",
      "Total cost of this query: 7.05e-05\n",
      "Total cost of this Runtime: 7.05e-05\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "chatbot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.01"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_cost * 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0100005"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_cost * 6667"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_cost = sum(in_cost) + sum(out_cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00007050\n"
     ]
    }
   ],
   "source": [
    "print(f'{final_cost:.8f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
